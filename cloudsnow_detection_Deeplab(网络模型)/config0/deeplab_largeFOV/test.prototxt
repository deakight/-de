#
name: "SIAM_FPM_cloud"
layer {
  name: "data"
  type: "ImageSegData"
  top: "data"
  top: "label"
  top: "data_dim"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 513
    mean_value: 104.008
    mean_value: 116.669
    mean_value: 122.675
  }
  image_data_param {
    root_folder: "${DATA_ROOT}"
    source: "${EXP}/list/${TEST_SET}.txt"
    batch_size: 1
    label_type: NONE
  }
}
###############################
layer {
  name: "conv1_1_3x3_s2"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1_3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv1_1_3x3_s2/bn"
  type: "BN"
  bottom: "conv1_1_3x3_s2"
  top: "conv1_1_3x3_s2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv1_1_3x3_s2/relu"
  type: "ReLU"
  bottom: "conv1_1_3x3_s2"
  top: "conv1_1_3x3_s2"
}
layer {
  name: "conv1_2_3x3"
  type: "Convolution"
  bottom: "conv1_1_3x3_s2"
  top: "conv1_2_3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv1_2_3x3/bn"
  type: "BN"
  bottom: "conv1_2_3x3"
  top: "conv1_2_3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv1_2_3x3/relu"
  type: "ReLU"
  bottom: "conv1_2_3x3"
  top: "conv1_2_3x3"
}
layer {
  name: "conv1_3_3x3"
  type: "Convolution"
  bottom: "conv1_2_3x3"
  top: "conv1_3_3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv1_3_3x3/bn"
  type: "BN"
  bottom: "conv1_3_3x3"
  top: "conv1_3_3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv1_3_3x3/relu"
  type: "ReLU"
  bottom: "conv1_3_3x3"
  top: "conv1_3_3x3"
}
layer {
  name: "pool1_3x3_s2"
  type: "Pooling"
  bottom: "conv1_3_3x3"
  top: "pool1_3x3_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "conv2_1_1x1_reduce"
  type: "Convolution"
  bottom: "pool1_3x3_s2"
  top: "conv2_1_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv2_1_1x1_reduce/bn"
  type: "BN"
  bottom: "conv2_1_1x1_reduce"
  top: "conv2_1_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv2_1_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv2_1_1x1_reduce"
  top: "conv2_1_1x1_reduce"
}
layer {
  name: "conv2_1_3x3"
  type: "Convolution"
  bottom: "conv2_1_1x1_reduce"
  top: "conv2_1_3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv2_1_3x3/bn"
  type: "BN"
  bottom: "conv2_1_3x3"
  top: "conv2_1_3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv2_1_3x3/relu"
  type: "ReLU"
  bottom: "conv2_1_3x3"
  top: "conv2_1_3x3"
}
layer {
  name: "conv2_1_1x1_increase"
  type: "Convolution"
  bottom: "conv2_1_3x3"
  top: "conv2_1_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv2_1_1x1_increase/bn"
  type: "BN"
  bottom: "conv2_1_1x1_increase"
  top: "conv2_1_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv2_1_1x1_proj"
  type: "Convolution"
  bottom: "pool1_3x3_s2"
  top: "conv2_1_1x1_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv2_1_1x1_proj/bn"
  type: "BN"
  bottom: "conv2_1_1x1_proj"
  top: "conv2_1_1x1_proj"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv2_1"
  type: "Eltwise"
  bottom: "conv2_1_1x1_proj"
  bottom: "conv2_1_1x1_increase"
  top: "conv2_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_1/relu"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2_1x1_reduce"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv2_2_1x1_reduce/bn"
  type: "BN"
  bottom: "conv2_2_1x1_reduce"
  top: "conv2_2_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv2_2_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv2_2_1x1_reduce"
  top: "conv2_2_1x1_reduce"
}
layer {
  name: "conv2_2_3x3"
  type: "Convolution"
  bottom: "conv2_2_1x1_reduce"
  top: "conv2_2_3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv2_2_3x3/bn"
  type: "BN"
  bottom: "conv2_2_3x3"
  top: "conv2_2_3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv2_2_3x3/relu"
  type: "ReLU"
  bottom: "conv2_2_3x3"
  top: "conv2_2_3x3"
}
layer {
  name: "conv2_2_1x1_increase"
  type: "Convolution"
  bottom: "conv2_2_3x3"
  top: "conv2_2_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv2_2_1x1_increase/bn"
  type: "BN"
  bottom: "conv2_2_1x1_increase"
  top: "conv2_2_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv2_2"
  type: "Eltwise"
  bottom: "conv2_1"
  bottom: "conv2_2_1x1_increase"
  top: "conv2_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_2/relu"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv2_3_1x1_reduce"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv2_3_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv2_3_1x1_reduce/bn"
  type: "BN"
  bottom: "conv2_3_1x1_reduce"
  top: "conv2_3_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv2_3_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv2_3_1x1_reduce"
  top: "conv2_3_1x1_reduce"
}
layer {
  name: "conv2_3_3x3"
  type: "Convolution"
  bottom: "conv2_3_1x1_reduce"
  top: "conv2_3_3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv2_3_3x3/bn"
  type: "BN"
  bottom: "conv2_3_3x3"
  top: "conv2_3_3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv2_3_3x3/relu"
  type: "ReLU"
  bottom: "conv2_3_3x3"
  top: "conv2_3_3x3"
}
layer {
  name: "conv2_3_1x1_increase"
  type: "Convolution"
  bottom: "conv2_3_3x3"
  top: "conv2_3_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv2_3_1x1_increase/bn"
  type: "BN"
  bottom: "conv2_3_1x1_increase"
  top: "conv2_3_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv2_3"
  type: "Eltwise"
  bottom: "conv2_2"
  bottom: "conv2_3_1x1_increase"
  top: "conv2_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_3/relu"
  type: "ReLU"
  bottom: "conv2_3"
  top: "conv2_3"
}
layer {
  name: "conv3_1_1x1_reduce"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv3_1_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv3_1_1x1_reduce/bn"
  type: "BN"
  bottom: "conv3_1_1x1_reduce"
  top: "conv3_1_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv3_1_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv3_1_1x1_reduce"
  top: "conv3_1_1x1_reduce"
}
layer {
  name: "conv3_1_3x3"
  type: "Convolution"
  bottom: "conv3_1_1x1_reduce"
  top: "conv3_1_3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv3_1_3x3/bn"
  type: "BN"
  bottom: "conv3_1_3x3"
  top: "conv3_1_3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv3_1_3x3/relu"
  type: "ReLU"
  bottom: "conv3_1_3x3"
  top: "conv3_1_3x3"
}
layer {
  name: "conv3_1_1x1_increase"
  type: "Convolution"
  bottom: "conv3_1_3x3"
  top: "conv3_1_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv3_1_1x1_increase/bn"
  type: "BN"
  bottom: "conv3_1_1x1_increase"
  top: "conv3_1_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv3_1_1x1_proj"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv3_1_1x1_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv3_1_1x1_proj/bn"
  type: "BN"
  bottom: "conv3_1_1x1_proj"
  top: "conv3_1_1x1_proj"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv3_1"
  type: "Eltwise"
  bottom: "conv3_1_1x1_proj"
  bottom: "conv3_1_1x1_increase"
  top: "conv3_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_1/relu"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2_1x1_reduce"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv3_2_1x1_reduce/bn"
  type: "BN"
  bottom: "conv3_2_1x1_reduce"
  top: "conv3_2_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv3_2_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv3_2_1x1_reduce"
  top: "conv3_2_1x1_reduce"
}
layer {
  name: "conv3_2_3x3"
  type: "Convolution"
  bottom: "conv3_2_1x1_reduce"
  top: "conv3_2_3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv3_2_3x3/bn"
  type: "BN"
  bottom: "conv3_2_3x3"
  top: "conv3_2_3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv3_2_3x3/relu"
  type: "ReLU"
  bottom: "conv3_2_3x3"
  top: "conv3_2_3x3"
}
layer {
  name: "conv3_2_1x1_increase"
  type: "Convolution"
  bottom: "conv3_2_3x3"
  top: "conv3_2_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv3_2_1x1_increase/bn"
  type: "BN"
  bottom: "conv3_2_1x1_increase"
  top: "conv3_2_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv3_2"
  type: "Eltwise"
  bottom: "conv3_1"
  bottom: "conv3_2_1x1_increase"
  top: "conv3_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_2/relu"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3_1x1_reduce"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv3_3_1x1_reduce/bn"
  type: "BN"
  bottom: "conv3_3_1x1_reduce"
  top: "conv3_3_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv3_3_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv3_3_1x1_reduce"
  top: "conv3_3_1x1_reduce"
}
layer {
  name: "conv3_3_3x3"
  type: "Convolution"
  bottom: "conv3_3_1x1_reduce"
  top: "conv3_3_3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv3_3_3x3/bn"
  type: "BN"
  bottom: "conv3_3_3x3"
  top: "conv3_3_3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv3_3_3x3/relu"
  type: "ReLU"
  bottom: "conv3_3_3x3"
  top: "conv3_3_3x3"
}
layer {
  name: "conv3_3_1x1_increase"
  type: "Convolution"
  bottom: "conv3_3_3x3"
  top: "conv3_3_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv3_3_1x1_increase/bn"
  type: "BN"
  bottom: "conv3_3_1x1_increase"
  top: "conv3_3_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv3_3"
  type: "Eltwise"
  bottom: "conv3_2"
  bottom: "conv3_3_1x1_increase"
  top: "conv3_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_3/relu"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}

layer {
  name: "conv3_4_1x1_reduce"
  type: "Convolution"
  bottom: "conv3_3"
  top: "conv3_4_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv3_4_1x1_reduce/bn"
  type: "BN"
  bottom: "conv3_4_1x1_reduce"
  top: "conv3_4_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv3_4_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv3_4_1x1_reduce"
  top: "conv3_4_1x1_reduce"
}
layer {
  name: "conv3_4_3x3"
  type: "Convolution"
  bottom: "conv3_4_1x1_reduce"
  top: "conv3_4_3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv3_4_3x3/bn"
  type: "BN"
  bottom: "conv3_4_3x3"
  top: "conv3_4_3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv3_4_3x3/relu"
  type: "ReLU"
  bottom: "conv3_4_3x3"
  top: "conv3_4_3x3"
}
layer {
  name: "conv3_4_1x1_increase"
  type: "Convolution"
  bottom: "conv3_4_3x3"
  top: "conv3_4_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv3_4_1x1_increase/bn"
  type: "BN"
  bottom: "conv3_4_1x1_increase"
  top: "conv3_4_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv3_4"
  type: "Eltwise"
  bottom: "conv3_3"
  bottom: "conv3_4_1x1_increase"
  top: "conv3_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_4/relu"
  type: "ReLU"
  bottom: "conv3_4"
  top: "conv3_4"
}

#####################################################
layer {
  name: "conv4_1_1x1_reduce"
  type: "Convolution"
  bottom: "conv3_4"
  top: "conv4_1_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv4_1_1x1_reduce/bn"
  type: "BN"
  bottom: "conv4_1_1x1_reduce"
  top: "conv4_1_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv4_1_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv4_1_1x1_reduce"
  top: "conv4_1_1x1_reduce"
}
layer {
  name: "conv4_1_3x3"
  type: "Convolution"
  bottom: "conv4_1_1x1_reduce"
  top: "conv4_1_3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 2
    dilation: 2
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv4_1_3x3/bn"
  type: "BN"
  bottom: "conv4_1_3x3"
  top: "conv4_1_3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv4_1_3x3/relu"
  type: "ReLU"
  bottom: "conv4_1_3x3"
  top: "conv4_1_3x3"
}
layer {
  name: "conv4_1_1x1_increase"
  type: "Convolution"
  bottom: "conv4_1_3x3"
  top: "conv4_1_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv4_1_1x1_increase/bn"
  type: "BN"
  bottom: "conv4_1_1x1_increase"
  top: "conv4_1_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv4_1_1x1_proj"
  type: "Convolution"
  bottom: "conv3_4"
  top: "conv4_1_1x1_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv4_1_1x1_proj/bn"
  type: "BN"
  bottom: "conv4_1_1x1_proj"
  top: "conv4_1_1x1_proj"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv4_1"
  type: "Eltwise"
  bottom: "conv4_1_1x1_proj"
  bottom: "conv4_1_1x1_increase"
  top: "conv4_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_1/relu"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2_1x1_reduce"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv4_2_1x1_reduce/bn"
  type: "BN"
  bottom: "conv4_2_1x1_reduce"
  top: "conv4_2_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv4_2_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv4_2_1x1_reduce"
  top: "conv4_2_1x1_reduce"
}
layer {
  name: "conv4_2_3x3"
  type: "Convolution"
  bottom: "conv4_2_1x1_reduce"
  top: "conv4_2_3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 2
    dilation: 2
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv4_2_3x3/bn"
  type: "BN"
  bottom: "conv4_2_3x3"
  top: "conv4_2_3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv4_2_3x3/relu"
  type: "ReLU"
  bottom: "conv4_2_3x3"
  top: "conv4_2_3x3"
}
layer {
  name: "conv4_2_1x1_increase"
  type: "Convolution"
  bottom: "conv4_2_3x3"
  top: "conv4_2_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv4_2_1x1_increase/bn"
  type: "BN"
  bottom: "conv4_2_1x1_increase"
  top: "conv4_2_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv4_2"
  type: "Eltwise"
  bottom: "conv4_1"
  bottom: "conv4_2_1x1_increase"
  top: "conv4_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_2/relu"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3_1x1_reduce"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv4_3_1x1_reduce/bn"
  type: "BN"
  bottom: "conv4_3_1x1_reduce"
  top: "conv4_3_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv4_3_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv4_3_1x1_reduce"
  top: "conv4_3_1x1_reduce"
}
layer {
  name: "conv4_3_3x3"
  type: "Convolution"
  bottom: "conv4_3_1x1_reduce"
  top: "conv4_3_3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 2
    dilation: 2
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv4_3_3x3/bn"
  type: "BN"
  bottom: "conv4_3_3x3"
  top: "conv4_3_3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv4_3_3x3/relu"
  type: "ReLU"
  bottom: "conv4_3_3x3"
  top: "conv4_3_3x3"
}
layer {
  name: "conv4_3_1x1_increase"
  type: "Convolution"
  bottom: "conv4_3_3x3"
  top: "conv4_3_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv4_3_1x1_increase/bn"
  type: "BN"
  bottom: "conv4_3_1x1_increase"
  top: "conv4_3_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv4_3"
  type: "Eltwise"
  bottom: "conv4_2"
  bottom: "conv4_3_1x1_increase"
  top: "conv4_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_3/relu"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "conv4_4_1x1_reduce"
  type: "Convolution"
  bottom: "conv4_3"
  top: "conv4_4_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv4_4_1x1_reduce/bn"
  type: "BN"
  bottom: "conv4_4_1x1_reduce"
  top: "conv4_4_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv4_4_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv4_4_1x1_reduce"
  top: "conv4_4_1x1_reduce"
}
layer {
  name: "conv4_4_3x3"
  type: "Convolution"
  bottom: "conv4_4_1x1_reduce"
  top: "conv4_4_3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 2
    dilation: 2
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv4_4_3x3/bn"
  type: "BN"
  bottom: "conv4_4_3x3"
  top: "conv4_4_3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv4_4_3x3/relu"
  type: "ReLU"
  bottom: "conv4_4_3x3"
  top: "conv4_4_3x3"
}
layer {
  name: "conv4_4_1x1_increase"
  type: "Convolution"
  bottom: "conv4_4_3x3"
  top: "conv4_4_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv4_4_1x1_increase/bn"
  type: "BN"
  bottom: "conv4_4_1x1_increase"
  top: "conv4_4_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv4_4"
  type: "Eltwise"
  bottom: "conv4_3"
  bottom: "conv4_4_1x1_increase"
  top: "conv4_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_4/relu"
  type: "ReLU"
  bottom: "conv4_4"
  top: "conv4_4"
}
layer {
  name: "conv4_5_1x1_reduce"
  type: "Convolution"
  bottom: "conv4_4"
  top: "conv4_5_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv4_5_1x1_reduce/bn"
  type: "BN"
  bottom: "conv4_5_1x1_reduce"
  top: "conv4_5_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv4_5_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv4_5_1x1_reduce"
  top: "conv4_5_1x1_reduce"
}
layer {
  name: "conv4_5_3x3"
  type: "Convolution"
  bottom: "conv4_5_1x1_reduce"
  top: "conv4_5_3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 2
    dilation: 2
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv4_5_3x3/bn"
  type: "BN"
  bottom: "conv4_5_3x3"
  top: "conv4_5_3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv4_5_3x3/relu"
  type: "ReLU"
  bottom: "conv4_5_3x3"
  top: "conv4_5_3x3"
}
layer {
  name: "conv4_5_1x1_increase"
  type: "Convolution"
  bottom: "conv4_5_3x3"
  top: "conv4_5_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv4_5_1x1_increase/bn"
  type: "BN"
  bottom: "conv4_5_1x1_increase"
  top: "conv4_5_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv4_5"
  type: "Eltwise"
  bottom: "conv4_4"
  bottom: "conv4_5_1x1_increase"
  top: "conv4_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_5/relu"
  type: "ReLU"
  bottom: "conv4_5"
  top: "conv4_5"
}
layer {
  name: "conv4_6_1x1_reduce"
  type: "Convolution"
  bottom: "conv4_5"
  top: "conv4_6_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv4_6_1x1_reduce/bn"
  type: "BN"
  bottom: "conv4_6_1x1_reduce"
  top: "conv4_6_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv4_6_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv4_6_1x1_reduce"
  top: "conv4_6_1x1_reduce"
}
layer {
  name: "conv4_6_3x3"
  type: "Convolution"
  bottom: "conv4_6_1x1_reduce"
  top: "conv4_6_3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 2
    dilation: 2
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv4_6_3x3/bn"
  type: "BN"
  bottom: "conv4_6_3x3"
  top: "conv4_6_3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv4_6_3x3/relu"
  type: "ReLU"
  bottom: "conv4_6_3x3"
  top: "conv4_6_3x3"
}
layer {
  name: "conv4_6_1x1_increase"
  type: "Convolution"
  bottom: "conv4_6_3x3"
  top: "conv4_6_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv4_6_1x1_increase/bn"
  type: "BN"
  bottom: "conv4_6_1x1_increase"
  top: "conv4_6_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv4_6"
  type: "Eltwise"
  bottom: "conv4_5"
  bottom: "conv4_6_1x1_increase"
  top: "conv4_6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_6/relu"
  type: "ReLU"
  bottom: "conv4_6"
  top: "conv4_6"
}
########################################################
layer {
  name: "conv5_1_1x1_reduce"
  type: "Convolution"
  bottom: "conv4_6"
  top: "conv5_1_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv5_1_1x1_reduce/bn"
  type: "BN"
  bottom: "conv5_1_1x1_reduce"
  top: "conv5_1_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv5_1_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv5_1_1x1_reduce"
  top: "conv5_1_1x1_reduce"
}
layer {
  name: "conv5_1_3x3"
  type: "Convolution"
  bottom: "conv5_1_1x1_reduce"
  top: "conv5_1_3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 4
    dilation: 4
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv5_1_3x3/bn"
  type: "BN"
  bottom: "conv5_1_3x3"
  top: "conv5_1_3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv5_1_3x3/relu"
  type: "ReLU"
  bottom: "conv5_1_3x3"
  top: "conv5_1_3x3"
}
layer {
  name: "conv5_1_1x1_increase"
  type: "Convolution"
  bottom: "conv5_1_3x3"
  top: "conv5_1_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 2048
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv5_1_1x1_increase/bn"
  type: "BN"
  bottom: "conv5_1_1x1_increase"
  top: "conv5_1_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv5_1_1x1_proj"
  type: "Convolution"
  bottom: "conv4_6"
  top: "conv5_1_1x1_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 2048
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv5_1_1x1_proj/bn"
  type: "BN"
  bottom: "conv5_1_1x1_proj"
  top: "conv5_1_1x1_proj"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv5_1"
  type: "Eltwise"
  bottom: "conv5_1_1x1_proj"
  bottom: "conv5_1_1x1_increase"
  top: "conv5_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv5_1/relu"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2_1x1_reduce"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv5_2_1x1_reduce/bn"
  type: "BN"
  bottom: "conv5_2_1x1_reduce"
  top: "conv5_2_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv5_2_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv5_2_1x1_reduce"
  top: "conv5_2_1x1_reduce"
}
layer {
  name: "conv5_2_3x3"
  type: "Convolution"
  bottom: "conv5_2_1x1_reduce"
  top: "conv5_2_3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 4
    dilation: 4
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv5_2_3x3/bn"
  type: "BN"
  bottom: "conv5_2_3x3"
  top: "conv5_2_3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv5_2_3x3/relu"
  type: "ReLU"
  bottom: "conv5_2_3x3"
  top: "conv5_2_3x3"
}
layer {
  name: "conv5_2_1x1_increase"
  type: "Convolution"
  bottom: "conv5_2_3x3"
  top: "conv5_2_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 2048
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv5_2_1x1_increase/bn"
  type: "BN"
  bottom: "conv5_2_1x1_increase"
  top: "conv5_2_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv5_2"
  type: "Eltwise"
  bottom: "conv5_1"
  bottom: "conv5_2_1x1_increase"
  top: "conv5_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv5_2/relu"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3_1x1_reduce"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv5_3_1x1_reduce/bn"
  type: "BN"
  bottom: "conv5_3_1x1_reduce"
  top: "conv5_3_1x1_reduce"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv5_3_1x1_reduce/relu"
  type: "ReLU"
  bottom: "conv5_3_1x1_reduce"
  top: "conv5_3_1x1_reduce"
}
layer {
  name: "conv5_3_3x3"
  type: "Convolution"
  bottom: "conv5_3_1x1_reduce"
  top: "conv5_3_3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 4
    dilation: 4
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv5_3_3x3/bn"
  type: "BN"
  bottom: "conv5_3_3x3"
  top: "conv5_3_3x3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv5_3_3x3/relu"
  type: "ReLU"
  bottom: "conv5_3_3x3"
  top: "conv5_3_3x3"
}
layer {
  name: "conv5_3_1x1_increase"
  type: "Convolution"
  bottom: "conv5_3_3x3"
  top: "conv5_3_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 2048
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv5_3_1x1_increase/bn"
  type: "BN"
  bottom: "conv5_3_1x1_increase"
  top: "conv5_3_1x1_increase"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv5_3"
  type: "Eltwise"
  bottom: "conv5_2"
  bottom: "conv5_3_1x1_increase"
  top: "conv5_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv5_3/relu"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}

###############################################################################################

############# ARM ##############
layer {
  name: "pool5_3/gap"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5_3/gap"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc5_3/sqz"
  type: "InnerProduct"
  bottom: "pool5_3/gap"
  top: "fc5_3/sqz"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "relu5_3/sqz"
  type: "ReLU"
  bottom: "fc5_3/sqz"
  top: "fc5_3/sqz"
}
layer {
  name: "fc5_3/exc"
  type: "InnerProduct"
  bottom: "fc5_3/sqz"
  top: "fc5_3/exc"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "sigm5_3/gate"
  type: "Sigmoid"
  bottom: "fc5_3/exc"
  top: "fc5_3/exc"
}
layer {
  name: "scale5_3"
  type: "Scale"
  bottom: "conv5_3"
  bottom: "fc5_3/exc"
  top: "scale5_3"
  scale_param {
    axis: 0
    bias_term: false
  }
}
##########################
layer {
  name: "pool5_3/gap/interp"
  type: "Interp"
  bottom: "pool5_3/gap"
  top: "pool5_3/gap/interp"
  interp_param {
    height:17
    width:17
  }
}

#######################
layer {
  name: "Eltwise_SUM"
  type: "Eltwise"
  bottom: "pool5_3/gap/interp"
  bottom: "scale5_3"
  top: "Eltwise_SUM"
}

#############################################


layer {
  name: "conv_XX_1"
  type: "Convolution"
  bottom: "Eltwise_SUM"
  top: "conv_XX_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_XX_1/bn"
  type: "BN"
  bottom: "conv_XX_1"
  top: "conv_XX_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_XX_1/relu"
  type: "ReLU"
  bottom: "conv_XX_1"
  top: "conv_XX_1"
}
####################################### ARM0 #############################################

layer {
  name: "pool_XX_1/gap"
  type: "Pooling"
  bottom: "conv_XX_1"
  top: "pool_XX_1/gap"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc_XX_1/sqz"
  type: "InnerProduct"
  bottom: "pool_XX_1/gap"
  top: "fc_XX_1/sqz"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 32
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "relu_XX_1/sqz"
  type: "ReLU"
  bottom: "fc_XX_1/sqz"
  top: "fc_XX_1/sqz"
}
layer {
  name: "fc_XX_1/exc"
  type: "InnerProduct"
  bottom: "fc_XX_1/sqz"
  top: "fc_XX_1/exc"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "sigm_XX_1/gate"
  type: "Sigmoid"
  bottom: "fc_XX_1/exc"
  top: "fc_XX_1/exc"
}
layer {
  name: "scale_XX_1"
  type: "Scale"
  bottom: "conv_XX_1"
  bottom: "fc_XX_1/exc"
  top: "scale_XX_1"
  scale_param {
    axis: 0
    bias_term: false
  }
}




##########################################################################


layer {
  name: "conv_XX_2"
  type: "Convolution"
  bottom: "conv4_6"
  top: "conv_XX_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_XX_2/bn"
  type: "BN"
  bottom: "conv_XX_2"
  top: "conv_XX_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_XX_2/relu"
  type: "ReLU"
  bottom: "conv_XX_2"
  top: "conv_XX_2"
}

############## Interp ##################

layer {
    name: "scale_XX_1_interp"
    type: "Interp"
    bottom: "scale_XX_1"
    top: "scale_XX_1_interp"
    interp_param {
    zoom_factor: 2
   }
}



################# SIAM1 ########################################################################################


layer {
  name: "concat_siam_1"
  type: "Concat"
  bottom: "conv_XX_2"
  bottom: "scale_XX_1_interp"
  top: "concat_input_siam_1"
}
###############conv_siam_siam_1_2 ############
layer {
  name: "conv_siam_1_1"
  type: "Convolution"
  bottom: "concat_input_siam_1"
  top: "conv_siam_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_siam_1_1/bn"
  type: "BN"
  bottom: "conv_siam_1_1"
  top: "conv_siam_1_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_1_1/relu"
  type: "ReLU"
  bottom: "conv_siam_1_1"
  top: "conv_siam_1_1"
}
###############conv_siam_1_2 ############
layer {
  name: "conv_siam_1_2"
  type: "Convolution"
  bottom: "conv_siam_1_1"
  top: "conv_siam_1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

############ residual unit 1 ###################

layer {
  name: "conv_siam_1_2/bn"
  type: "BN"
  bottom: "conv_siam_1_2"
  top: "conv_siam_1_2/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_1_2/relu"
  type: "ReLU"
  bottom: "conv_siam_1_2/bn"
  top: "conv_siam_1_2/bn/relu"
}
###############
layer {
  name: "conv_siam_1_residualunit_1_1"
  type: "Convolution"
  bottom: "conv_siam_1_2/bn/relu"
  top: "conv_siam_1_residualunit_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_siam_1_residualunit_1_1/bn"
  type: "BN"
  bottom: "conv_siam_1_residualunit_1_1"
  top: "conv_siam_1_residualunit_1_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_1_residualunit_1_1/relu"
  type: "ReLU"
  bottom: "conv_siam_1_residualunit_1_1"
  top: "conv_siam_1_residualunit_1_1"
}

layer {
  name: "conv_siam_1_residualunit_1_2"
  type: "Convolution"
  bottom: "conv_siam_1_residualunit_1_1"
  top: "conv_siam_1_residualunit_1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_siam_1_residualunit_1_2/bn"
  type: "BN"
  bottom: "conv_siam_1_residualunit_1_2"
  top: "conv_siam_1_residualunit_1_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_1_residualunit_1_2/relu"
  type: "ReLU"
  bottom: "conv_siam_1_residualunit_1_2"
  top: "conv_siam_1_residualunit_1_2"
}
layer {
  name: "conv_siam_1_residualunit_1_3"
  type: "Convolution"
  bottom: "conv_siam_1_residualunit_1_2"
  top: "conv_siam_1_residualunit_1_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  name: "conv_siam_1_Eltwise_sum_1"
  type: "Eltwise"
  bottom: "conv_siam_1_residualunit_1_3"
  bottom: "conv_siam_1_2"
  top: "conv_siam_1_2_residualunit_sum"
  eltwise_param {
    operation: SUM
  }
}
##############################
layer{
	name: "conv_siam_1_2_interp"
	type: "Interp"
	bottom: "conv_siam_1_2_residualunit_sum"
	top: "conv_siam_1_2_residualunit_sum_interp"
	interp_param {
    zoom_factor: 2
   }
}


layer {
  name: "conv_siam_1_2_residualunit_sum_interp/bn"
  type: "BN"
  bottom: "conv_siam_1_2_residualunit_sum_interp"
  top: "conv_siam_1_2_residualunit_sum_interp"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_1_2_residualunit_sum_interp/relu"
  type: "ReLU"
  bottom: "conv_siam_1_2_residualunit_sum_interp"
  top: "conv_siam_1_2_residualunit_sum_interp"
}
layer {
  name: "conv_siam_1_3"
  type: "Convolution"
  bottom: "conv_siam_1_2_residualunit_sum_interp"
  top: "conv_siam_1_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_siam_1_3/bn"
  type: "BN"
  bottom: "conv_siam_1_3"
  top: "conv_siam_1_3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_1_3/relu"
  type: "ReLU"
  bottom: "conv_siam_1_3"
  top: "conv_siam_1_3"
}
##################
layer {
  name: "conv_siam_1_4"
  type: "Convolution"
  bottom: "conv_siam_1_3"
  top: "conv_siam_1_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  name: "conv_siam_1_sigm"
  type: "Sigmoid"
  bottom: "conv_siam_1_4"
  top: "conv_siam_1_4/Sigmoid"
}

layer 
{
  name: "conv_siam_1_Eltwise_mul"
  type: "Eltwise"
  bottom: "conv_siam_1_1"
  bottom: "conv_siam_1_4/Sigmoid"
  top: "conv_siam_1_1/mul"
  eltwise_param {
    operation: PROD
  }
}
############################# CNN 1 ###################################################################

layer {
  name: "conv_CNN1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv_CNN1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_CNN1_1/bn"
  type: "BN"
  bottom: "conv_CNN1_1"
  top: "conv_CNN1_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_CNN1_1/relu"
  type: "ReLU"
  bottom: "conv_CNN1_1"
  top: "conv_CNN1_1"
}

####################
layer {
  name: "conv_CNN1_2"
  type: "Convolution"
  bottom: "conv_CNN1_1"
  top: "conv_CNN1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_CNN1_2/bn"
  type: "BN"
  bottom: "conv_CNN1_2"
  top: "conv_CNN1_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_CNN1_2/relu"
  type: "ReLU"
  bottom: "conv_CNN1_2"
  top: "conv_CNN1_2"
}
######################
layer {
  name: "conv_CNN1_3"
  type: "Convolution"
  bottom: "conv_CNN1_2"
  top: "conv_CNN1_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_CNN1_3/bn"
  type: "BN"
  bottom: "conv_CNN1_3"
  top: "conv_CNN1_3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_CNN1_3/relu"
  type: "ReLU"
  bottom: "conv_CNN1_3"
  top: "conv_CNN1_3"
}
################
layer {
  name: "conv_CNN1_4"
  type: "Convolution"
  bottom: "conv_CNN1_3"
  top: "conv_CNN1_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_CNN1_4/bn"
  type: "BN"
  bottom: "conv_CNN1_4"
  top: "conv_CNN1_4"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_CNN1_4/relu"
  type: "ReLU"
  bottom: "conv_CNN1_4"
  top: "conv_CNN1_4"
}

##########################SIAM2 ###################################

################# SIAM1 ########################################################################################


layer {
  name: "concat_siam_2"
  type: "Concat"
  bottom: "conv_CNN1_4"
  bottom: "scale_XX_1_interp"
  top: "concat_input_siam_2"
}
###############conv_siam_siam_2_2 ############
layer {
  name: "conv_siam_2_1"
  type: "Convolution"
  bottom: "concat_input_siam_2"
  top: "conv_siam_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_siam_2_1/bn"
  type: "BN"
  bottom: "conv_siam_2_1"
  top: "conv_siam_2_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_2_1/relu"
  type: "ReLU"
  bottom: "conv_siam_2_1"
  top: "conv_siam_2_1"
}
###############conv_siam_2_2 ############
layer {
  name: "conv_siam_2_2"
  type: "Convolution"
  bottom: "conv_siam_2_1"
  top: "conv_siam_2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

############ residual unit 1 ###################

layer {
  name: "conv_siam_2_2/bn"
  type: "BN"
  bottom: "conv_siam_2_2"
  top: "conv_siam_2_2/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_2_2/relu"
  type: "ReLU"
  bottom: "conv_siam_2_2/bn"
  top: "conv_siam_2_2/bn/relu"
}
###############
layer {
  name: "conv_siam_2_residualunit_1_1"
  type: "Convolution"
  bottom: "conv_siam_2_2/bn/relu"
  top: "conv_siam_2_residualunit_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_siam_2_residualunit_1_1/bn"
  type: "BN"
  bottom: "conv_siam_2_residualunit_1_1"
  top: "conv_siam_2_residualunit_1_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_2_residualunit_1_1/relu"
  type: "ReLU"
  bottom: "conv_siam_2_residualunit_1_1"
  top: "conv_siam_2_residualunit_1_1"
}

layer {
  name: "conv_siam_2_residualunit_1_2"
  type: "Convolution"
  bottom: "conv_siam_2_residualunit_1_1"
  top: "conv_siam_2_residualunit_1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_siam_2_residualunit_1_2/bn"
  type: "BN"
  bottom: "conv_siam_2_residualunit_1_2"
  top: "conv_siam_2_residualunit_1_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_2_residualunit_1_2/relu"
  type: "ReLU"
  bottom: "conv_siam_2_residualunit_1_2"
  top: "conv_siam_2_residualunit_1_2"
}
layer {
  name: "conv_siam_2_residualunit_1_3"
  type: "Convolution"
  bottom: "conv_siam_2_residualunit_1_2"
  top: "conv_siam_2_residualunit_1_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  name: "conv_siam_2_Eltwise_sum_1"
  type: "Eltwise"
  bottom: "conv_siam_2_residualunit_1_3"
  bottom: "conv_siam_2_2"
  top: "conv_siam_2_2_residualunit_sum"
  eltwise_param {
    operation: SUM
  }
}
##############################
layer{
	name: "conv_siam_2_2_interp"
	type: "Interp"
	bottom: "conv_siam_2_2_residualunit_sum"
	top: "conv_siam_2_2_residualunit_sum_interp"
	interp_param {
    zoom_factor: 2
   }
}
layer {
  name: "conv_siam_2_2_residualunit_sum_interp/bn"
  type: "BN"
  bottom: "conv_siam_2_2_residualunit_sum_interp"
  top: "conv_siam_2_2_residualunit_sum_interp"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_2_2_residualunit_sum_interp/relu"
  type: "ReLU"
  bottom: "conv_siam_2_2_residualunit_sum_interp"
  top: "conv_siam_2_2_residualunit_sum_interp"
}
layer {
  name: "conv_siam_2_3"
  type: "Convolution"
  bottom: "conv_siam_2_2_residualunit_sum_interp"
  top: "conv_siam_2_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_siam_2_3/bn"
  type: "BN"
  bottom: "conv_siam_2_3"
  top: "conv_siam_2_3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_2_3/relu"
  type: "ReLU"
  bottom: "conv_siam_2_3"
  top: "conv_siam_2_3"
}
##################
layer {
  name: "conv_siam_2_4"
  type: "Convolution"
  bottom: "conv_siam_2_3"
  top: "conv_siam_2_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  name: "conv_siam_2_sigm"
  type: "Sigmoid"
  bottom: "conv_siam_2_4"
  top: "conv_siam_2_4/Sigmoid"
}

layer 
{
  name: "conv_siam_2_Eltwise_mul"
  type: "Eltwise"
  bottom: "conv_siam_2_1"
  bottom: "conv_siam_2_4/Sigmoid"
  top: "conv_siam_2_1/mul"
  eltwise_param {
    operation: PROD
  }
}


####################### concat_01 ######################################


layer {
  name: "concat_01"
  type: "Concat"
  bottom: "conv_siam_1_1/mul"
  bottom: "scale_XX_1_interp"
  bottom: "conv_siam_2_1/mul"
  top: "concat_01"
}
#############################################################################################################################
layer {
  name: "conv_XX_3"
  type: "Convolution"
  bottom: "concat_01"
  top: "conv_XX_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output:512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_XX_3/bn"
  type: "BN"
  bottom: "conv_XX_3"
  top: "conv_XX_3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_XX_3/relu"
  type: "ReLU"
  bottom: "conv_XX_3"
  top: "conv_XX_3"
}
################# ARM2 ####################

layer {
  name: "pool_XX_3/gap"
  type: "Pooling"
  bottom: "conv_XX_3"
  top: "pool_XX_3/gap"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc_XX_3/sqz"
  type: "InnerProduct"
  bottom: "pool_XX_3/gap"
  top: "fc_XX_3/sqz"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 32
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "relu_XX_3/sqz"
  type: "ReLU"
  bottom: "fc_XX_3/sqz"
  top: "fc_XX_3/sqz"
}
layer {
  name: "fc_XX_3/exc"
  type: "InnerProduct"
  bottom: "fc_XX_3/sqz"
  top: "fc_XX_3/exc"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "sigm_XX_3/gate"
  type: "Sigmoid"
  bottom: "fc_XX_3/exc"
  top: "fc_XX_3/exc"
}
layer {
  name: "scale_XX_3"
  type: "Scale"
  bottom: "conv_XX_3"
  bottom: "fc_XX_3/exc"
  top: "scale_XX_3"
  scale_param {
    axis: 0
    bias_term: false
  }
}

##############################################
layer {
    name: "scale_XX_3_interp"
    type: "Interp"
    bottom: "scale_XX_3"
    top: "scale_XX_3_interp"
    interp_param {
    zoom_factor: 2
   }
}

######################################################
layer {
  name: "conv_XX_4"
  type: "Convolution"
  bottom: "conv3_4"
  top: "conv_XX_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output:512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_XX_4/bn"
  type: "BN"
  bottom: "conv_XX_4"
  top: "conv_XX_4"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_XX_4/relu"
  type: "ReLU"
  bottom: "conv_XX_4"
  top: "conv_XX_4"
}
###################################

################# SIAM3 ########################################################################################


layer {
  name: "concat_siam_3"
  type: "Concat"
  bottom: "scale_XX_3_interp"
  bottom: "conv_XX_4"
  top: "concat_input_siam_3"
}
###############conv_siam_siam_3_2 ############
layer {
  name: "conv_siam_3_1"
  type: "Convolution"
  bottom: "concat_input_siam_3"
  top: "conv_siam_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_siam_3_1/bn"
  type: "BN"
  bottom: "conv_siam_3_1"
  top: "conv_siam_3_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_3_1/relu"
  type: "ReLU"
  bottom: "conv_siam_3_1"
  top: "conv_siam_3_1"
}
###############conv_siam_3_2 ############
layer {
  name: "conv_siam_3_2"
  type: "Convolution"
  bottom: "conv_siam_3_1"
  top: "conv_siam_3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

############ residual unit 1 ###################

layer {
  name: "conv_siam_3_2/bn"
  type: "BN"
  bottom: "conv_siam_3_2"
  top: "conv_siam_3_2/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_3_2/relu"
  type: "ReLU"
  bottom: "conv_siam_3_2/bn"
  top: "conv_siam_3_2/bn/relu"
}
###############
layer {
  name: "conv_siam_3_residualunit_1_1"
  type: "Convolution"
  bottom: "conv_siam_3_2/bn/relu"
  top: "conv_siam_3_residualunit_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_siam_3_residualunit_1_1/bn"
  type: "BN"
  bottom: "conv_siam_3_residualunit_1_1"
  top: "conv_siam_3_residualunit_1_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_3_residualunit_1_1/relu"
  type: "ReLU"
  bottom: "conv_siam_3_residualunit_1_1"
  top: "conv_siam_3_residualunit_1_1"
}

layer {
  name: "conv_siam_3_residualunit_1_2"
  type: "Convolution"
  bottom: "conv_siam_3_residualunit_1_1"
  top: "conv_siam_3_residualunit_1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_siam_3_residualunit_1_2/bn"
  type: "BN"
  bottom: "conv_siam_3_residualunit_1_2"
  top: "conv_siam_3_residualunit_1_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_3_residualunit_1_2/relu"
  type: "ReLU"
  bottom: "conv_siam_3_residualunit_1_2"
  top: "conv_siam_3_residualunit_1_2"
}
layer {
  name: "conv_siam_3_residualunit_1_3"
  type: "Convolution"
  bottom: "conv_siam_3_residualunit_1_2"
  top: "conv_siam_3_residualunit_1_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  name: "conv_siam_3_Eltwise_sum_1"
  type: "Eltwise"
  bottom: "conv_siam_3_residualunit_1_3"
  bottom: "conv_siam_3_2"
  top: "conv_siam_3_2_residualunit_sum"
  eltwise_param {
    operation: SUM
  }
}
##############################
layer{
	name: "conv_siam_3_2_interp"
	type: "Interp"
	bottom: "conv_siam_3_2_residualunit_sum"
	top: "conv_siam_3_2_residualunit_sum_interp"
	interp_param {
    zoom_factor: 2
   }
}



layer {
  name: "conv_siam_3_2_residualunit_sum_interp/bn"
  type: "BN"
  bottom: "conv_siam_3_2_residualunit_sum_interp"
  top: "conv_siam_3_2_residualunit_sum_interp"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_3_2_residualunit_sum_interp/relu"
  type: "ReLU"
  bottom: "conv_siam_3_2_residualunit_sum_interp"
  top: "conv_siam_3_2_residualunit_sum_interp"
}
layer {
  name: "conv_siam_3_3"
  type: "Convolution"
  bottom: "conv_siam_3_2_residualunit_sum_interp"
  top: "conv_siam_3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_siam_3_3/bn"
  type: "BN"
  bottom: "conv_siam_3_3"
  top: "conv_siam_3_3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_3_3/relu"
  type: "ReLU"
  bottom: "conv_siam_3_3"
  top: "conv_siam_3_3"
}
##################
layer {
  name: "conv_siam_3_4"
  type: "Convolution"
  bottom: "conv_siam_3_3"
  top: "conv_siam_3_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  name: "conv_siam_3_sigm"
  type: "Sigmoid"
  bottom: "conv_siam_3_4"
  top: "conv_siam_3_4/Sigmoid"
}

layer 
{
  name: "conv_siam_3_Eltwise_mul"
  type: "Eltwise"
  bottom: "conv_siam_3_1"
  bottom: "conv_siam_3_4/Sigmoid"
  top: "conv_siam_3_1/mul"
  eltwise_param {
    operation: PROD
  }
}
####################CNN 2########################

############################# CNN 1 ###################################################################

layer {
  name: "conv_CNN2_1"
  type: "Convolution"
  bottom: "data"
  top: "conv_CNN2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_CNN2_1/bn"
  type: "BN"
  bottom: "conv_CNN2_1"
  top: "conv_CNN2_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_CNN2_1/relu"
  type: "ReLU"
  bottom: "conv_CNN2_1"
  top: "conv_CNN2_1"
}

####################
layer {
  name: "conv_CNN2_2"
  type: "Convolution"
  bottom: "conv_CNN2_1"
  top: "conv_CNN2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_CNN2_2/bn"
  type: "BN"
  bottom: "conv_CNN2_2"
  top: "conv_CNN2_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_CNN2_2/relu"
  type: "ReLU"
  bottom: "conv_CNN2_2"
  top: "conv_CNN2_2"
}
######################
layer {
  name: "conv_CNN2_3"
  type: "Convolution"
  bottom: "conv_CNN2_2"
  top: "conv_CNN2_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_CNN2_3/bn"
  type: "BN"
  bottom: "conv_CNN2_3"
  top: "conv_CNN2_3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_CNN2_3/relu"
  type: "ReLU"
  bottom: "conv_CNN2_3"
  top: "conv_CNN2_3"
}
################## SIAM4 ###############
################# SIAM1 ########################################################################################


layer {
  name: "concat_siam_4"
  type: "Concat"
  bottom: "scale_XX_3_interp"
  bottom: "conv_CNN2_3"
  top: "concat_input_siam_4"
}
###############conv_siam_siam_4_2 ############
layer {
  name: "conv_siam_4_1"
  type: "Convolution"
  bottom: "concat_input_siam_4"
  top: "conv_siam_4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_siam_4_1/bn"
  type: "BN"
  bottom: "conv_siam_4_1"
  top: "conv_siam_4_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_4_1/relu"
  type: "ReLU"
  bottom: "conv_siam_4_1"
  top: "conv_siam_4_1"
}
###############conv_siam_4_2 ############
layer {
  name: "conv_siam_4_2"
  type: "Convolution"
  bottom: "conv_siam_4_1"
  top: "conv_siam_4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

############ residual unit 1 ###################

layer {
  name: "conv_siam_4_2/bn"
  type: "BN"
  bottom: "conv_siam_4_2"
  top: "conv_siam_4_2/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_4_2/relu"
  type: "ReLU"
  bottom: "conv_siam_4_2/bn"
  top: "conv_siam_4_2/bn/relu"
}
###############
layer {
  name: "conv_siam_4_residualunit_1_1"
  type: "Convolution"
  bottom: "conv_siam_4_2/bn/relu"
  top: "conv_siam_4_residualunit_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_siam_4_residualunit_1_1/bn"
  type: "BN"
  bottom: "conv_siam_4_residualunit_1_1"
  top: "conv_siam_4_residualunit_1_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_4_residualunit_1_1/relu"
  type: "ReLU"
  bottom: "conv_siam_4_residualunit_1_1"
  top: "conv_siam_4_residualunit_1_1"
}

layer {
  name: "conv_siam_4_residualunit_1_2"
  type: "Convolution"
  bottom: "conv_siam_4_residualunit_1_1"
  top: "conv_siam_4_residualunit_1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_siam_4_residualunit_1_2/bn"
  type: "BN"
  bottom: "conv_siam_4_residualunit_1_2"
  top: "conv_siam_4_residualunit_1_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_4_residualunit_1_2/relu"
  type: "ReLU"
  bottom: "conv_siam_4_residualunit_1_2"
  top: "conv_siam_4_residualunit_1_2"
}
layer {
  name: "conv_siam_4_residualunit_1_3"
  type: "Convolution"
  bottom: "conv_siam_4_residualunit_1_2"
  top: "conv_siam_4_residualunit_1_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  name: "conv_siam_4_Eltwise_sum_1"
  type: "Eltwise"
  bottom: "conv_siam_4_residualunit_1_3"
  bottom: "conv_siam_4_2"
  top: "conv_siam_4_2_residualunit_sum"
  eltwise_param {
    operation: SUM
  }
}
##############################
layer{
	name: "conv_siam_4_2_interp"
	type: "Interp"
	bottom: "conv_siam_4_2_residualunit_sum"
	top: "conv_siam_4_2_residualunit_sum_interp"
	interp_param {
    zoom_factor: 2
   }
}
layer {
  name: "conv_siam_4_2_residualunit_sum_interp/bn"
  type: "BN"
  bottom: "conv_siam_4_2_residualunit_sum_interp"
  top: "conv_siam_4_2_residualunit_sum_interp"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_4_2_residualunit_sum_interp/relu"
  type: "ReLU"
  bottom: "conv_siam_4_2_residualunit_sum_interp"
  top: "conv_siam_4_2_residualunit_sum_interp"
}
layer {
  name: "conv_siam_4_3"
  type: "Convolution"
  bottom: "conv_siam_4_2_residualunit_sum_interp"
  top: "conv_siam_4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_siam_4_3/bn"
  type: "BN"
  bottom: "conv_siam_4_3"
  top: "conv_siam_4_3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_4_3/relu"
  type: "ReLU"
  bottom: "conv_siam_4_3"
  top: "conv_siam_4_3"
}
##################
layer {
  name: "conv_siam_4_4"
  type: "Convolution"
  bottom: "conv_siam_4_3"
  top: "conv_siam_4_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  name: "conv_siam_4_sigm"
  type: "Sigmoid"
  bottom: "conv_siam_4_4"
  top: "conv_siam_4_4/Sigmoid"
}

layer 
{
  name: "conv_siam_4_Eltwise_mul"
  type: "Eltwise"
  bottom: "conv_siam_4_1"
  bottom: "conv_siam_4_4/Sigmoid"
  top: "conv_siam_4_1/mul"
  eltwise_param {
    operation: PROD
  }
}
#####################concat 02 ########################################

layer {
  name: "concat_02"
  type: "Concat"
  bottom: "scale_XX_3_interp"
  bottom: "conv_siam_3_1/mul"
  bottom: "conv_siam_4_1/mul"
  top: "concat_02"
}
############################################################################################

layer {
  name: "conv_XX_5"
  type: "Convolution"
  bottom: "concat_02"
  top: "conv_XX_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output:512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_XX_5/bn"
  type: "BN"
  bottom: "conv_XX_5"
  top: "conv_XX_5"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_XX_5/relu"
  type: "ReLU"
  bottom: "conv_XX_5"
  top: "conv_XX_5"
}
##################### ARM3 #####################
layer {
  name: "pool_XX_5/gap"
  type: "Pooling"
  bottom: "conv_XX_5"
  top: "pool_XX_5/gap"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc_XX_5/sqz"
  type: "InnerProduct"
  bottom: "pool_XX_5/gap"
  top: "fc_XX_5/sqz"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 32
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "relu_XX_5/sqz"
  type: "ReLU"
  bottom: "fc_XX_5/sqz"
  top: "fc_XX_5/sqz"
}
layer {
  name: "fc_XX_5/exc"
  type: "InnerProduct"
  bottom: "fc_XX_5/sqz"
  top: "fc_XX_5/exc"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "sigm_XX_5/gate"
  type: "Sigmoid"
  bottom: "fc_XX_5/exc"
  top: "fc_XX_5/exc"
}
layer {
  name: "scale_XX_5"
  type: "Scale"
  bottom: "conv_XX_5"
  bottom: "fc_XX_5/exc"
  top: "scale_XX_5"
  scale_param {
    axis: 0
    bias_term: false
  }
}


###############################

layer {
    name: "scale_XX_5_interp"
    type: "Interp"
    bottom: "scale_XX_5"
    top: "scale_XX_5_interp"
    interp_param {
    zoom_factor: 2
   }
}

###############################

layer {
  name: "conv_XX_6"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv_XX_6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output:512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_XX_6/bn"
  type: "BN"
  bottom: "conv_XX_6"
  top: "conv_XX_6"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_XX_6/relu"
  type: "ReLU"
  bottom: "conv_XX_6"
  top: "conv_XX_6"
}
################################# SIAM5 ##############################################

################# SIAM1 ########################################################################################


layer {
  name: "concat_siam_5"
  type: "Concat"
  bottom: "scale_XX_5_interp"
  bottom: "conv_XX_6"
  top: "concat_input_siam_5"
}
###############conv_siam_siam_5_2 ############
layer {
  name: "conv_siam_5_1"
  type: "Convolution"
  bottom: "concat_input_siam_5"
  top: "conv_siam_5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_siam_5_1/bn"
  type: "BN"
  bottom: "conv_siam_5_1"
  top: "conv_siam_5_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_5_1/relu"
  type: "ReLU"
  bottom: "conv_siam_5_1"
  top: "conv_siam_5_1"
}
###############conv_siam_5_2 ############
layer {
  name: "conv_siam_5_2"
  type: "Convolution"
  bottom: "conv_siam_5_1"
  top: "conv_siam_5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

############ residual unit 1 ###################

layer {
  name: "conv_siam_5_2/bn"
  type: "BN"
  bottom: "conv_siam_5_2"
  top: "conv_siam_5_2/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_5_2/relu"
  type: "ReLU"
  bottom: "conv_siam_5_2/bn"
  top: "conv_siam_5_2/bn/relu"
}
###############
layer {
  name: "conv_siam_5_residualunit_1_1"
  type: "Convolution"
  bottom: "conv_siam_5_2/bn/relu"
  top: "conv_siam_5_residualunit_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_siam_5_residualunit_1_1/bn"
  type: "BN"
  bottom: "conv_siam_5_residualunit_1_1"
  top: "conv_siam_5_residualunit_1_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_5_residualunit_1_1/relu"
  type: "ReLU"
  bottom: "conv_siam_5_residualunit_1_1"
  top: "conv_siam_5_residualunit_1_1"
}

layer {
  name: "conv_siam_5_residualunit_1_2"
  type: "Convolution"
  bottom: "conv_siam_5_residualunit_1_1"
  top: "conv_siam_5_residualunit_1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_siam_5_residualunit_1_2/bn"
  type: "BN"
  bottom: "conv_siam_5_residualunit_1_2"
  top: "conv_siam_5_residualunit_1_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_5_residualunit_1_2/relu"
  type: "ReLU"
  bottom: "conv_siam_5_residualunit_1_2"
  top: "conv_siam_5_residualunit_1_2"
}
layer {
  name: "conv_siam_5_residualunit_1_3"
  type: "Convolution"
  bottom: "conv_siam_5_residualunit_1_2"
  top: "conv_siam_5_residualunit_1_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  name: "conv_siam_5_Eltwise_sum_1"
  type: "Eltwise"
  bottom: "conv_siam_5_residualunit_1_3"
  bottom: "conv_siam_5_2"
  top: "conv_siam_5_2_residualunit_sum"
  eltwise_param {
    operation: SUM
  }
}
##############################
layer{
	name: "conv_siam_5_2_interp"
	type: "Interp"
	bottom: "conv_siam_5_2_residualunit_sum"
	top: "conv_siam_5_2_residualunit_sum_interp"
	interp_param {
    zoom_factor: 2
   }
}
layer {
  name: "conv_siam_5_2_residualunit_sum_interp/bn"
  type: "BN"
  bottom: "conv_siam_5_2_residualunit_sum_interp"
  top: "conv_siam_5_2_residualunit_sum_interp"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_5_2_residualunit_sum_interp/relu"
  type: "ReLU"
  bottom: "conv_siam_5_2_residualunit_sum_interp"
  top: "conv_siam_5_2_residualunit_sum_interp"
}
layer {
  name: "conv_siam_5_3"
  type: "Convolution"
  bottom: "conv_siam_5_2_residualunit_sum_interp"
  top: "conv_siam_5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_siam_5_3/bn"
  type: "BN"
  bottom: "conv_siam_5_3"
  top: "conv_siam_5_3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_5_3/relu"
  type: "ReLU"
  bottom: "conv_siam_5_3"
  top: "conv_siam_5_3"
}
##################
layer {
  name: "conv_siam_5_4"
  type: "Convolution"
  bottom: "conv_siam_5_3"
  top: "conv_siam_5_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  name: "conv_siam_5_sigm"
  type: "Sigmoid"
  bottom: "conv_siam_5_4"
  top: "conv_siam_5_4/Sigmoid"
}

layer 
{
  name: "conv_siam_5_Eltwise_mul"
  type: "Eltwise"
  bottom: "conv_siam_5_1"
  bottom: "conv_siam_5_4/Sigmoid"
  top: "conv_siam_5_1/mul"
  eltwise_param {
    operation: PROD
  }
}
######################## CNN 3 #############################

############################# CNN 3 ###################################################################

layer {
  name: "conv_CNN3_1"
  type: "Convolution"
  bottom: "data"
  top: "conv_CNN3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_CNN3_1/bn"
  type: "BN"
  bottom: "conv_CNN3_1"
  top: "conv_CNN3_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_CNN3_1/relu"
  type: "ReLU"
  bottom: "conv_CNN3_1"
  top: "conv_CNN3_1"
}

####################
layer {
  name: "conv_CNN3_2"
  type: "Convolution"
  bottom: "conv_CNN3_1"
  top: "conv_CNN3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_CNN3_2/bn"
  type: "BN"
  bottom: "conv_CNN3_2"
  top: "conv_CNN3_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_CNN3_2/relu"
  type: "ReLU"
  bottom: "conv_CNN3_2"
  top: "conv_CNN3_2"
}
######################
layer {
  name: "conv_CNN3_3"
  type: "Convolution"
  bottom: "conv_CNN3_2"
  top: "conv_CNN3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_CNN3_3/bn"
  type: "BN"
  bottom: "conv_CNN3_3"
  top: "conv_CNN3_3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_CNN3_3/relu"
  type: "ReLU"
  bottom: "conv_CNN3_3"
  top: "conv_CNN3_3"
}

################# SIAM6 ########################################################################################


layer {
  name: "concat_siam_6"
  type: "Concat"
  bottom: "scale_XX_5_interp"
  bottom: "conv_CNN3_3"
  top: "concat_input_siam_6"
}
###############conv_siam_siam_6_2 ############
layer {
  name: "conv_siam_6_1"
  type: "Convolution"
  bottom: "concat_input_siam_6"
  top: "conv_siam_6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_siam_6_1/bn"
  type: "BN"
  bottom: "conv_siam_6_1"
  top: "conv_siam_6_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_6_1/relu"
  type: "ReLU"
  bottom: "conv_siam_6_1"
  top: "conv_siam_6_1"
}
###############conv_siam_6_2 ############
layer {
  name: "conv_siam_6_2"
  type: "Convolution"
  bottom: "conv_siam_6_1"
  top: "conv_siam_6_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

############ residual unit 1 ###################

layer {
  name: "conv_siam_6_2/bn"
  type: "BN"
  bottom: "conv_siam_6_2"
  top: "conv_siam_6_2/bn"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_6_2/relu"
  type: "ReLU"
  bottom: "conv_siam_6_2/bn"
  top: "conv_siam_6_2/bn/relu"
}
###############
layer {
  name: "conv_siam_6_residualunit_1_1"
  type: "Convolution"
  bottom: "conv_siam_6_2/bn/relu"
  top: "conv_siam_6_residualunit_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_siam_6_residualunit_1_1/bn"
  type: "BN"
  bottom: "conv_siam_6_residualunit_1_1"
  top: "conv_siam_6_residualunit_1_1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_6_residualunit_1_1/relu"
  type: "ReLU"
  bottom: "conv_siam_6_residualunit_1_1"
  top: "conv_siam_6_residualunit_1_1"
}

layer {
  name: "conv_siam_6_residualunit_1_2"
  type: "Convolution"
  bottom: "conv_siam_6_residualunit_1_1"
  top: "conv_siam_6_residualunit_1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_siam_6_residualunit_1_2/bn"
  type: "BN"
  bottom: "conv_siam_6_residualunit_1_2"
  top: "conv_siam_6_residualunit_1_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_6_residualunit_1_2/relu"
  type: "ReLU"
  bottom: "conv_siam_6_residualunit_1_2"
  top: "conv_siam_6_residualunit_1_2"
}
layer {
  name: "conv_siam_6_residualunit_1_3"
  type: "Convolution"
  bottom: "conv_siam_6_residualunit_1_2"
  top: "conv_siam_6_residualunit_1_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  name: "conv_siam_6_Eltwise_sum_1"
  type: "Eltwise"
  bottom: "conv_siam_6_residualunit_1_3"
  bottom: "conv_siam_6_2"
  top: "conv_siam_6_2_residualunit_sum"
  eltwise_param {
    operation: SUM
  }
}
##############################
layer{
	name: "conv_siam_6_2_interp"
	type: "Interp"
	bottom: "conv_siam_6_2_residualunit_sum"
	top: "conv_siam_6_2_residualunit_sum_interp"
	interp_param {
    zoom_factor: 2
   }
}
layer {
  name: "conv_siam_6_2_residualunit_sum_interp/bn"
  type: "BN"
  bottom: "conv_siam_6_2_residualunit_sum_interp"
  top: "conv_siam_6_2_residualunit_sum_interp"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_6_2_residualunit_sum_interp/relu"
  type: "ReLU"
  bottom: "conv_siam_6_2_residualunit_sum_interp"
  top: "conv_siam_6_2_residualunit_sum_interp"
}
layer {
  name: "conv_siam_6_3"
  type: "Convolution"
  bottom: "conv_siam_6_2_residualunit_sum_interp"
  top: "conv_siam_6_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "conv_siam_6_3/bn"
  type: "BN"
  bottom: "conv_siam_6_3"
  top: "conv_siam_6_3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "conv_siam_6_3/relu"
  type: "ReLU"
  bottom: "conv_siam_6_3"
  top: "conv_siam_6_3"
}
##################
layer {
  name: "conv_siam_6_4"
  type: "Convolution"
  bottom: "conv_siam_6_3"
  top: "conv_siam_6_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  name: "conv_siam_6_sigm"
  type: "Sigmoid"
  bottom: "conv_siam_6_4"
  top: "conv_siam_6_4/Sigmoid"
}

layer 
{
  name: "conv_siam_6_Eltwise_mul"
  type: "Eltwise"
  bottom: "conv_siam_6_1"
  bottom: "conv_siam_6_4/Sigmoid"
  top: "conv_siam_6_1/mul"
  eltwise_param {
    operation: PROD
  }
}


############################## concat_03 ########################################
layer {
  name: "concat_03"
  type: "Concat"
  bottom: "scale_XX_5_interp"
  bottom: "conv_siam_5_1/mul"
  bottom: "conv_siam_6_1/mul"
  top: "concat_03"
}
############################## ARM 4 ###############################################

layer {
  name: "pool_concat_03/gap"
  type: "Pooling"
  bottom: "concat_03"
  top: "pool_concat_03/gap"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc_concat_03/sqz"
  type: "InnerProduct"
  bottom: "pool_concat_03/gap"
  top: "fc_concat_03/sqz"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 96
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "relu_concat_03/sqz"
  type: "ReLU"
  bottom: "fc_concat_03/sqz"
  top: "fc_concat_03/sqz"
}
layer {
  name: "fc_concat_03/exc"
  type: "InnerProduct"
  bottom: "fc_concat_03/sqz"
  top: "fc_concat_03/exc"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 1536
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "sigm_concat_03/gate"
  type: "Sigmoid"
  bottom: "fc_concat_03/exc"
  top: "fc_concat_03/exc"
}
layer {
  name: "scale_concat_03"
  type: "Scale"
  bottom: "concat_03"
  bottom: "fc_concat_03/exc"
  top: "scale_concat_03"
  scale_param {
    axis: 0
    bias_term: false
  }
}

########################################################################
############################### FPM  ######################################

######################################conv_XX_7_pool1############################
layer {
  name: "conv_XX_7_pool1"
  type: "Pooling"
  bottom: "scale_concat_03"
  top: "conv_XX_7_pool1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
##########conv_XX_7_pool1_conv##########
layer {
  name: "conv_XX_7_pool1_conv"
  type: "Convolution"
  bottom: "conv_XX_7_pool1"
  top: "conv_XX_7_pool1_conv"
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
#########conv_XX_7_pool1_conv/bn##########
layer {
  name: "conv_XX_7_pool1_conv/bn"
  type: "BN"
  bottom: "conv_XX_7_pool1_conv"
  top: "conv_XX_7_pool1_conv"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
##########conv_XX_7_pool1_conv/relu#########
layer {
  name: "conv_XX_7_pool1_conv/relu"
  type: "ReLU"
  bottom: "conv_XX_7_pool1_conv"
  top: "conv_XX_7_pool1_conv"
}
###########conv_XX_7_pool1_interp##########
layer {
  name: "conv_XX_7_pool1_interp"
  type: "Interp"
  bottom: "conv_XX_7_pool1_conv"
  top: "conv_XX_7_pool1_interp"
  interp_param {
    height: 129
    width: 129
  }
}
###################### hole = 0 ##########################
layer {
  name: "conv_XX_7_fc_1"
  type: "Convolution"
  bottom: "scale_concat_03"
  top: "conv_XX_7_fc_1"
  param {
    lr_mult: 2
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    stride: 1
    kernel_size: 1
  }
}

#########conv_XX_7_fc_1/bn##########
layer {
  name: "conv_XX_7_fc_1/bn"
  type: "BN"
  bottom: "conv_XX_7_fc_1"
  top: "conv_XX_7_fc_1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}


layer {
  name: "relu5_3_fc_1"
  type: "ReLU"
  bottom: "conv_XX_7_fc_1"
  top: "conv_XX_7_fc_1"
}
layer {
  name: "drop5_3_fc_1"
  type: "Dropout"
  bottom: "conv_XX_7_fc_1"
  top: "conv_XX_7_fc_1"
  dropout_param {
    dropout_ratio: 0.3
  }
}


####################### hole = 6 ####################
layer {
  name: "conv_XX_7_fc_2"
  type: "Convolution"
  bottom: "scale_concat_03"
  top: "conv_XX_7_fc_2"
  param {
    lr_mult: 2
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 6
    kernel_size: 3
    dilation: 6
  }
}
#########conv_XX_7_fc_2/bn##########
layer {
  name: "conv_XX_7_fc_2/bn"
  type: "BN"
  bottom: "conv_XX_7_fc_2"
  top: "conv_XX_7_fc_2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}


layer {
  name: "relu5_3_fc_2"
  type: "ReLU"
  bottom: "conv_XX_7_fc_2"
  top: "conv_XX_7_fc_2"
}
layer {
  name: "drop5_3_fc_2"
  type: "Dropout"
  bottom: "conv_XX_7_fc_2"
  top: "conv_XX_7_fc_2"
  dropout_param {
    dropout_ratio: 0.3
  }
}

################# hole = 12 ######################
layer {
  name: "conv_XX_7_fc_3"
  type: "Convolution"
  bottom: "scale_concat_03"
  top: "conv_XX_7_fc_3"
  param {
    lr_mult: 2
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 12
    kernel_size: 3
    dilation: 12
  }
}
#########conv_XX_7_fc_3/bn##########
layer {
  name: "conv_XX_7_fc_3/bn"
  type: "BN"
  bottom: "conv_XX_7_fc_3"
  top: "conv_XX_7_fc_3"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}

layer {
  name: "relu5_3_fc_3"
  type: "ReLU"
  bottom: "conv_XX_7_fc_3"
  top: "conv_XX_7_fc_3"
}
layer {
  name: "drop5_3_fc_3"
  type: "Dropout"
  bottom: "conv_XX_7_fc_3"
  top: "conv_XX_7_fc_3"
  dropout_param {
    dropout_ratio: 0.3
  }
}


################### hole = 18 #############################
layer {
  name: "conv_XX_7_fc_4"
  type: "Convolution"
  bottom: "scale_concat_03"
  top: "conv_XX_7_fc_4"
  param {
    lr_mult: 2
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 18
    kernel_size: 3
    dilation: 18
  }
}
#########conv_XX_7_fc_4/bn##########
layer {
  name: "conv_XX_7_fc_4/bn"
  type: "BN"
  bottom: "conv_XX_7_fc_4"
  top: "conv_XX_7_fc_4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bn_param {
    slope_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    frozen: true
    momentum: 0.95
  }
}
layer {
  name: "relu5_3_fc_4"
  type: "ReLU"
  bottom: "conv_XX_7_fc_4"
  top: "conv_XX_7_fc_4"
}
layer {
  name: "drop5_3_fc_4"
  type: "Dropout"
  bottom: "conv_XX_7_fc_4"
  top: "conv_XX_7_fc_4"
  dropout_param {
    dropout_ratio: 0.3
  }
}

############################ conv_XX_7_concat ###############################################
layer {
  name: "conv_XX_7_concat"
  type: "Concat"
  bottom: "conv_XX_7_pool1_interp"
  bottom: "scale_concat_03"
  bottom: "conv_XX_7_fc_1"
  bottom: "conv_XX_7_fc_2"
  bottom: "conv_XX_7_fc_3"
  bottom: "conv_XX_7_fc_4"
  top: "conv_XX_7_concat"
}

######################### OUTPUT1 ################################

layer {
  name: "conv_XX_8"
  type: "Convolution"
  bottom: "conv_XX_7_concat"
  top: "conv_XX_8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output:4
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}



###############################
## original resolution
layer {
    name: "Inter_conv_XX_8"
    type: "Interp"
    bottom: "conv_XX_8"
    top: "Inter_conv_XX_8"
    interp_param {
    zoom_factor: 4
   }
}
########################################

layer {
  name: "fc8_mat"
  type: "MatWrite"
  bottom: "Inter_conv_XX_8"
  include {
    phase: TEST
  }
  mat_write_param {
    prefix: "${FEATURE_DIR}/${TEST_SET}/fc8/"
    source: "${EXP}/list/${TEST_SET}_id.txt"
    strip: 0
    period: 1
  }
}
layer {
  name: "silence"
  type: "Silence"
  bottom: "label"
  bottom: "data_dim"
}

